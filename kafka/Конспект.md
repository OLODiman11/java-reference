### Обработка запрос асинхронно

```java
CompletableFuture<SendResult<String, productCreatedEvent>> future = kafkaTemplate.send("prodict-created-events-topic", productId, productCreatedEvent);
future.whenComplete((res, exc) -> {
    if(exc != null) {
        log.error("Error");
    } else {
        log.info("Success");
    }
})
log.info("Return");
```

Логи:

```text
Return
Success
```

### Обработка запрос синхронно

```java
SendResult<String, productCreatedEvent> result = kafkaTemplate.send("prodict-created-events-topic", productId, productCreatedEvent).get();
```

## Настройка Producer

```properties
# Сервера продюсеров
spring.kafka.producer.bootstrap-servers=localhost:9092,localhost:9094
# Сериализатор ключа
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
# Сериализатор значения
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
```

### Настроить повторные запросы

```properties
# Количество повторов
spring.kafka.producer.retries=3
# Время ожидания перед повторной отправкой неудачного запроса
spring.kafka.producer.properties.retry.backoff.ms=5000
# Максимальное количество времени на повторные запросы
spring.kafka.producer.properties.delivery.timeout.ms=60000
# Время, в течение которого накапливаются сообщения перед отправкой
spring.kafka.producer.properties.delivery.linger.ms=0
# Как долго producer ждет ответа от брокера
spring.kafka.producer.properties.request.timeout.ms=30000

# delivery.timeout.ms >= linger.ms + request.timeout.ms
```

### Настроить acknowledgement

```properties
# Ожидать acknowledgement от всех синхронизированных реплик
spring.kafka.producer.acks=all
```

### Настроить через Java

```java
import java.beans.BeanProperty;
import java.util.HashMap;

@Configuration
public class KafkaConfig {
    Map<String, object> producerConfig() {
        Map<String, Object> config = new HashMap<>();

        config.put(ProducerConfig.ACKS_CONFIG, acks);

        return config;
    }

    @Bean
    ProducerFactory<String, ProductCreatedEvent> producerFactory() {
        return new DefaultKafkaProducerFactory<>(producerConfig());
    }

    @Bean
    KafkaTemplate<String, ProductCreatedEvent> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```

### Настроить идемпотентность

```properties
spring.kafka.producer.properties.idempotence=true
```

## Настройка Consumer

```properties
# Сервера консюмеров
spring.kafka.consumer.bootstrap-servers=localhost:9092,localhost:9094
# Десериализатор ключа
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# Десериализатор значения
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
# Id группы
spring.kafka.consumer.group-id=product-created-events
# Доверенные пакеты (обрабатывать только ивенты, принадлежащий указанному пакету)
spring.kafka.consumer.properties.spring.json.trusted.packages=by.javaguru.ws.core
```

Обработка одного сообщения в топике

```java
@Component
public class ProductCreatedEventHandler {
    @KafkaListener(topics = "product-created-event-topic")
    public void handle(ProductCreatedEvent productCreatedEvent) {
        
    }
}
```

Обработка разных сообщений в одном топике

```java
@Component
@KafkaListener(topics = "product-created-event-topic")
public class ProductEventHandler {
    @KafkaHandler
    public void handle(ProductCreatedEvent productCreatedEvent) {
        
    }
}
```

### Настроить через Java

```java
import java.beans.BeanProperty;
import java.util.ConcurrentModificationException;
import java.util.HashMap;

@Configuration
public class KafkaConfig {

    @Bean
    ConsumerFactory<String, Object> producerFactory() {
        Map<String, Object> config = new HashMap<>();

        config.put(ConsumerConfig.GROUP_ID_CONFIG, "product-created-events");

        return new DefaultKafkaConsumerFactory<>(config);
    }

    @Bean
    ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(ConsumerFactory consumerFactory) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);
        return factory;
    }
}
```

## Обработка исключений

### Deserialization Exception

ErrorHandlingDeserializer позволяет избежать бесконечного прочтения неправильного сообщения. Если при обработке произошла ошибка десериализации, то консюмер перейдет к обработке следующего сообщения.

```java
config.put(ConsumerConfig.Value_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer.class);
config.put(ERRORHandlingDeserializer.VALUE_DESERIZLIZER_CLASS, JsonDeserializer.class);
```

Dead Letter Topic (DLT)

KafkaConfig

```java
@Bean
ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(ConsumerFactory consumerFactory, KafkaTemplate kafkaTemplate) {

    DefaultErrorHandler errorHandler = new DefaultErrorHandler(new DeadLetterPublishingRecoverer(kafkaTemplate));

    ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory);
    factory.setCommonErrorHandler();
    return factory;
}

@Bean
KafkaTemplate<String, Object> kafkaTemplate(ProducerFactory<String, Object> producerFactory) {
    return new KafkaTemplate<>(producerFactory);
}

@Bean
ProducerFactory<String, Object> producerFactory() {
    Map<String, Object> config = new HashMap<>();
    config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, ...);
    config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
    return new DefaultKafkaProducerFactory<>(config);
}

```

### Обработка внутренних исключений

```java
public class RetryableException extends RuntimeException {
    public RetryableException(String message) {
        super(message);
    }

    public RetryableException(Throwable cause) {
        super(cause);
    }
}
```

```java
public class NotRetryableException extends RuntimeException {
    public NotRetryableException(String message) {
        super(message);
    }

    public NotRetryableException(Throwable cause) {
        super(cause);
    }
}
```

KafkaConfig

```java
DefaultErrorHandler errorHandler = new DefaultErrorHandler(new DeadLetterPublishingRecoverer(kafkaTemplate), 
        new FixedBackOff(3000, 3)); // повторять каждые 3 сек, максимум 3 раза
errorHandler.addNotRetryableExceptions(NotRetryableException.class, ...);
errorHandler.addRetryableExceptions(RetryableException.class, ...);
```

### ConsumerGroup

```java
@KafkaListener(topics = "product-created-event-topic", groupId = "product-created-events")
```

или 

```properties
spring.kafka.consumer.group-id=product-created-events
```

или

```java
config.put(ConsumerConfig.GROUP_ID_CONFIG, "product-created-events");
```

### Настроить идемпотентность

Producer

```java
ProducerRecord<String, ProductCreatedEvent> record = new ProducerRecord<>(
        "product-created-events-topic",
        productId,
        productCreatedEvent
);

record.headers().add("messageId", UUID.randomUUID().toString().getBytes());

SendResult<String, ProductCreatedEvent> result = kafkaTemplate.send(record).get();
```

Consumer

```java
@KafkaHandler
public void handle(@Payload ProductCratedEvent productCratedEvent, 
                   @Header("messageId") String messageId) {
    
}
```

Transactional

```java
@Transactional
@KafkaHandler
public void handle() {
    ...
}
```

```java
@KafkaHandler
public void handle(@Payload ProductCratedEvent productCratedEvent, 
                   @Header("messageId") String messageId) {
    
}
```
